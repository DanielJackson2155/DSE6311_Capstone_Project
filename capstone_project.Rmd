---
title: "DSE6311 Capstone Project"
author: "Daniel Jackson, Nischal Panta, Nelson Tran"
date: "`r Sys.Date()`"
output: word_document
---

# Loading libraries 
```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
library(janitor)
library(DMwR2)
```


# Read in Data
```{r 1}
cov_df = read.csv("capstone_data.csv")

# Remove X variable, ResponseId variable
cov_df = cov_df[, -which(names(cov_df) == "X")]
cov_df = cov_df[, -which(names(cov_df) =="ResponseId")]

# We want to use snakecase on features and simplify features. Before we do that, we need to figure out what features we want to keep and what ones we want to get rid of.
# We already got rid of the X variable from converting our file to a CSV and the ResponseID.

# Data frame dimension
dim(cov_df)
# 2534 observations
# 57 variables

# Print names of variables in data set
colnames(cov_df)

# Check for NA values
colSums(is.na(cov_df))
```


We have multiple variables in our data set that appear more than once. Some of the "_group" variables are other variables in our data set grouped together based on the unique values of other features. For instance, there is a "Educ_Dad" variable and an "Educ_Dad_Group". These "_group" variables have one to three unique values while the the features being grouped have one to seven unique values. To avoid having collinearity with these, we well be removing the "_group" variables.
We also will remove the Classification and Classification_High variable. We will assign the Classification vector to a variable in our global environment just in case we want to compare our results later in our analysis. This variable used z-scores to determine if a student experienced low, medium, or high psychological impact from Covid-19.
Let us also remove the zip code variable. There is 601 NA values and we are not too worried about zip code as we know what college each student is attending.
We can also remove the Source_NCSU variable as our Source variable tells us what school each student attends.
Let us also remove the z-scores of students bad mood and lost time for our analysis.
```{r 3}
cov_df = cov_df[, -which(names(cov_df) =="Class_Self_group")]
cov_df = cov_df[, -which(names(cov_df) =="Class_Mom_group")]
cov_df = cov_df[, -which(names(cov_df) =="Class_Dad_group")]
cov_df = cov_df[, -which(names(cov_df) =="Income_Relative_group")]
cov_df = cov_df[, -which(names(cov_df) =="Educ_Mom_group")]
cov_df = cov_df[, -which(names(cov_df) =="Educ_Dad_group")]
cov_df = cov_df[, -which(names(cov_df) =="Health_General_group")]
cov_df = cov_df[, -which(names(cov_df) =="BMI_group")]
cov_df = cov_df[, -which(names(cov_df) =="Hrs_Outdoor_group")]
cov_df = cov_df[, -which(names(cov_df) =="Hrs_Screen_group")]
cov_df = cov_df[, -which(names(cov_df) =="Hrs_Exercise_group")]
cov_df = cov_df[, -which(names(cov_df) =="Age_18to25")]
cov_df = cov_df[, -which(names(cov_df) =="Age_3Groups")]
cov_df = cov_df[, -which(names(cov_df) =="Source_NCSU")]
cov_df = cov_df[, -which(names(cov_df) =="GIS_ZIP")]
cov_df = cov_df[, -which(names(cov_df) =="COVID_F1_BadMoods")]
cov_df = cov_df[, -which(names(cov_df) =="COVID_F2_LostTime")]

# Check for NAs again
colSums(is.na(cov_df))

# 280 NA values in Ethnoracial_Group, NHWhite_f, Ethnoracial_Group_White1_Asian2 
# 8 NA values in Age and Source

# Store Classification into empty vector for now. Might need to revisit this later and re-read in data if remove any observations. And then remove Classification and Classification_High
psycho_class = c()
pyscho_class = cov_df$Classification
cov_df = cov_df[, -which(names(cov_df) =="Classification")]
cov_df = cov_df[, -which(names(cov_df) =="Classification_High")]

# Check for NAs again
colSums(is.na(cov_df))

# Dimension
dim(cov_df)
# 2534 observations
# 38 variables
```


Now let us merge COVID_Afraid, COVID_Irritable, COVID_Guilty, COVID_Sad, COVID_Preoccupied and COVID_Stressed into one response variable called "total_anxiety_level". Before we do that, let us round each observation in each feature to nearest whole number.
```{r 4}
# Which features do we want to round up: COVID_Afraid, COVID_Irritable, COVID_Guilty, COVID_Sad, COVID_Preoccupied and COVID_Stressed
features_round_up = c("COVID_Afraid", "COVID_Irritable", "COVID_Guilty", "COVID_Sad", "COVID_Preoccupied", "COVID_Stressed")
cov_df = cov_df %>%
  mutate_at(vars(features_round_up), ~ ceiling(.))

# Now let us merge these into one variable called total_anxiety_level
cov_df = cov_df %>%
  mutate(total_anxiety_level = COVID_Afraid + COVID_Irritable + 
           COVID_Guilty + COVID_Sad + COVID_Preoccupied)

# Now, let us remove those variables added together from the data set
cov_df = cov_df %>%
  select(-any_of(features_round_up))

# Find average and median value of total_anxiety_level
avg_tot_anx_lev = mean(cov_df$total_anxiety_level)
# Mean is 251.17
med_tot_anx_lev = median(cov_df$total_anxiety_level)
# Median is 260

dim(cov_df)
# 2534 observations
# 33 Variables
```

Now, let us round any numeric value to then nearest whole number for ease of analysis.
```{r 5}
cov_df = cov_df %>%
  mutate_if(is.numeric, function(x) round(x))

# We do not have enough information from out data on the Type variable. Let us remove that.
# Also, the binary Educ_College_Grad can be derived from Educ_Self variable. Let us remove that as well.
# Since we already have a Ethnoracial_Group variable, we can remove Ethnoracial_Group_f, NHWhite_f and Ethnoracial_Group_White1_Asian2 
cov_df = cov_df[, -which(names(cov_df) =="Type")]
cov_df = cov_df[, -which(names(cov_df) =="Educ_College_Grad")]
cov_df = cov_df[, -which(names(cov_df) =="Ethnoracial_Group_f")]
cov_df = cov_df[, -which(names(cov_df) =="NHWhite_f")]
cov_df = cov_df[, -which(names(cov_df) =="Ethnoracial_Group_White1_Asian2")]

dim(cov_df)
# 2534 observations
# 28 variables

# Check for NAs again
colSums(is.na(cov_df))
# Ethnoracial_Group has 280 NA values
# Age has 8
```

Next, we need to clean up our features and convert them to snake case for ease of coding/analysis. Then need to decide how we want to handle any remaining NA values.
Please Install the Janitor Package if you haven't already, it allows for snake casing all the variables much easier
```{r 6}
#using the Janitor Package for snake casing each var
cov_df <- cov_df %>%
  clean_names(case = "snake")
```

We want to see what the dataset looks like, we can plot to see the spread of the data. 
We have character variables that can be turned into factors 
We also have integers which can also be turned into factors
Now the variables have levels.

We also have continuous variables which can be used to create histograms 
The categorical variables can be used to create bar plots
```{r 7}
# Convert character variables and integers to factors w/ levels
cov_df <- cov_df %>% 
  mutate_if(is.character, as.factor)

cov_df <- cov_df %>% 
  mutate_if(is.integer, as.factor)

# Function to create bar plots for categorical variables
plot_cat <- function(df, var) {
  ggplot(df, aes_string(x = var)) +
    geom_bar(fill = sample(colors(), 1)) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
      axis.title.x = element_text(size = 12, face = "bold"),
      axis.title.y = element_text(size = 12, face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1)
    ) +
    labs(title = paste("Count of", var), x = var, y = "Count")
}

# Function to create histograms for continuous variables
plot_cont <- function(df, var) {
  ggplot(df, aes_string(x = var)) +
    geom_histogram(binwidth = 1, fill = sample(colors(), 1), color = "black") +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
      axis.title.x = element_text(size = 12, face = "bold"),
      axis.title.y = element_text(size = 12, face = "bold")
    ) +
    labs(title = paste("Histogram of", var), x = var, y = "Frequency")
}

# Create two seperate datasets for ploting
cat_vars <- names(Filter(is.factor, cov_df))
cont_vars <- names(Filter(is.numeric, cov_df))

# Ploting icategorical variables
for (cat_vars in cat_vars) {
  print(plot_cat(cov_df, cat_vars))
}

# Ploting all continuous variables
for (cont_vars in cont_vars) {
  print(plot_cont(cov_df, cont_vars))
}
```
Upon looking at the data, we found that there are a lot of N/A's in "ethnoracial_group" and "age." We thought about either making another category (other) that we could assign to the N/A values or we could use K-nearest-neighbors (KNN) to fill in the missing values.

We wanted to use KNN to fill in the missing values.
```{r}
#Using K-nearest-neighbors to fill in the missing values
cov_df <- knnImputation(cov_df, k = 3)
#checking to see if there are any more N/a values
colSums(is.na(cov_df))
unique(cov_df$age)
unique(cov_df$ethnoracial_group)
```
I thought there there were a few observations that I would consider as outliers and wanted to get rid of them in the case that they will affect our models in a bad way.
```{r}
#creating a cut off for hours of exercise and then subsetting those that aren't wanted from the data frame
threshold_hrs_exercise <- 9 
cov_df <- subset(cov_df, hrs_exercise < threshold_hrs_exercise)
#creating an array of which ages that should be kept in the data frame
ages_to_keep <- c("18 to 24", "25 to 32", "33 to 44", "45 to 54", "55 to 64")
cov_df <- filter(cov_df, age %in% ages_to_keep)
```


We have 28 variables in our dataset so far and 25 of them are numerical. There is a chance our variables might be highly correlated to each other which could create issues with our models. To prevent that lets create a correlation matrix and then plot of all our numerical variables to investigate. We can choose a range to be able to see the highly corrolated values 
```{r}

# Let's select numerical variables again since we made a few edits since our last histogram
numeric_vars <- sapply(cov_df, is.numeric)
num_data <- cov_df[, numeric_vars]

# Creating a simple matrix for all our numerical variable
cor_matrix <- cor(num_data, use = "complete.obs")

print(cor_matrix)
# creating the correlation plot
# lets also make necessary adjustments to make the text smaller 
corrplot(cor_matrix, method = "color", type = "full", 
         tl.col = "black", tl.srt = 45, tl.cex = 0.8, 
         title = "Correlation Plot of Numerical Variables", mar = c(0, 0, 1, 0))


# variable "a" will of course be correlated with "a" so lets create a range for significantly correlated variables so absolute value of greater than 0.5 but less than absolute value of 0.99 so we do not get the 1 or -1 values. 
cor_matrix_range <- cor_matrix
cor_matrix_range[abs(cor_matrix_range) < 0.7 | abs(cor_matrix_range) >= 0.99] <- NA


# to get a table of only the values in our range we need to plug it back in 
cor_matrix_range_df <- as.data.frame(as.table(cor_matrix_range))

# lets filter the correlation for our range. Redudency
fil_cor_matrix_range_df <- cor_matrix_range_df %>%
  filter((Freq > 0.7 & Freq < 0.99) | (Freq < -0.7 & Freq > -0.99))


# now lets print the filtered correlations
print(fil_cor_matrix_range_df)


# lets repeat the plotting process
corrplot(cor_matrix_range, method = "color", type = "full", 
         tl.col = "black", tl.srt = 45, tl.cex = 0.8, 
         na.label = " ", 
         title = "Correlation Plot of Numerical Variables (0.7 < |r| < 0.99)", mar = c(0, 0, 1, 0))

```

Another test for multicollinearity is a VIF Variance Inflation Factor. This is a good measure of the amount of multicollinearity in a set of multiple regression variables. When multicollinearity exists it undermines the statistical significance of an independent variable, increases model complexity and can cause overfitting. It will also inflate the variance (standard error) of coefficient estimates

```{r}
# lets fit a linear model with all our numerical variables
multi_col_model <- lm(total_anxiety_level ~ ., data = num_data)

# now lets calculate the Variance Inflation Factor (VIF) to check if we have highly correlated variables. 
vif_values <- vif(multi_col_model)

# As we can see, all the values are fairly low. We are safe
print(vif_values)

```

